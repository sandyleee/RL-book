{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accurate-collective",
   "metadata": {},
   "source": [
    "# Assignment 3 - Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-karaoke",
   "metadata": {},
   "source": [
    "## Frog Escape Problem as MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-cruise",
   "metadata": {},
   "source": [
    "For the *frog-escape problem*, we have the state space $S = \\{0, 1, ..., n\\}$, the terminal states $T = \\{0, n\\}$, and the action space $A = \\{A, B\\}$ (croaking). \n",
    "\n",
    "We have the following transition probabilities $\\mathcal{P}(s,a,s') \\text{ for all } i \\in N$:\n",
    "\n",
    "$$\\mathcal{P}(i,A,i-1) = \\frac{i}{n}$$\n",
    "$$\\mathcal{P}(i,A,i+1) = \\frac{n-1}{i}$$\n",
    "$$\\mathcal{P}(i,B, s') = \\frac{1}{n} \\text{ for all }s' \\in \\{0,...,i-1,i+1,...n\\}$$\n",
    "\n",
    "All other transition probabilities are 0. Finally, we set the reward function $\\mathcal{R_T}(s,a,s')$ to be:\n",
    "\n",
    "$$\\mathcal{R_T}(i,A,n) = 1 \\text{ for all } i \\in N $$\n",
    "$$\\mathcal{R_T}(i,B,n) = 1 \\text{ for all } i \\in N $$\n",
    "\n",
    "Rewards for landing all other states are 0. Then, the only way to get any reward is by escaping (landing on n), and the Optimal Value Function will represent the probability of escaping the bond."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-harassment",
   "metadata": {},
   "source": [
    "## Modeling as Finite MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bright-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict\n",
    "from rl.markov_decision_process import FiniteMarkovDecisionProcess\n",
    "from rl.markov_decision_process import FinitePolicy, StateActionMapping\n",
    "from rl.markov_process import FiniteMarkovProcess, FiniteMarkovRewardProcess\n",
    "from rl.distribution import Categorical, Constant\n",
    "from scipy.stats import poisson\n",
    "import itertools\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "correct-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class PadState:\n",
    "    pad_num: int\n",
    "        \n",
    "PadTransMapping = StateActionMapping[PadState, int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "departmental-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrogEscMDP(FiniteMarkovDecisionProcess[PadState, int]):\n",
    "\n",
    "    def __init__(self, n: int):\n",
    "        self.n: int = n     \n",
    "        super().__init__(self.get_action_transition_reward_map())\n",
    "\n",
    "    def get_action_transition_reward_map(self) -> PadTransMapping:\n",
    "        d: Dict[PadState, Dict[str, Categorical[Tuple[PadState, float]]]] = {}\n",
    "        #define rewards\n",
    "        rewards: Dict[PadState, float] = {PadState(s): 0 for s in range(n)}\n",
    "        rewards[PadState(n)] = 1\n",
    "            \n",
    "        for state in range(1, self.n): #non-terminal states\n",
    "            #action -> state-reward -> p\n",
    "            d1: Dict[str, Categorical[Tuple[PadState, float]]] = {}\n",
    "            \n",
    "            #croaks A\n",
    "            #state-reward -> p (to be turned into Categorical)\n",
    "            sr_probs_dict_A: Dict[Tuple[PadState, float], float] = \\\n",
    "                {(PadState(state-1), rewards[state-1]): state/n, \\\n",
    "                (PadState(state+1), rewards[state+1]): (n-state)/n}\n",
    "            d1['A'] = Categorical(sr_probs_dict_A)\n",
    "            \n",
    "            #croaks B\n",
    "            sr_probs_dict_B: Dict[Tuple[PadState, float], float] = \\\n",
    "                {(PadState(next_state), rewards[next_state]): 1/n for next_state in range(n+1) if n != state}          \n",
    "            d1['B'] = Categorical(sr_probs_dict_B)\n",
    "\n",
    "            d[PadState(state)] = d1\n",
    "            \n",
    "        #terminal states\n",
    "        d[PadState(0)] = None\n",
    "        d[PadState(n)] = None\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "orange-ultimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDP Transition Map\n",
      "------------------\n",
      "From State PadState(pad_num=1):\n",
      "  With Action A:\n",
      "    To [State PadState(pad_num=0) and Reward 0.000] with Probability 0.167\n",
      "    To [State PadState(pad_num=2) and Reward 0.000] with Probability 0.833\n",
      "  With Action B:\n",
      "    To [State PadState(pad_num=0) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=1) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=2) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=3) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=4) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=5) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=6) and Reward 1.000] with Probability 0.143\n",
      "From State PadState(pad_num=2):\n",
      "  With Action A:\n",
      "    To [State PadState(pad_num=1) and Reward 0.000] with Probability 0.333\n",
      "    To [State PadState(pad_num=3) and Reward 0.000] with Probability 0.667\n",
      "  With Action B:\n",
      "    To [State PadState(pad_num=0) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=1) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=2) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=3) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=4) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=5) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=6) and Reward 1.000] with Probability 0.143\n",
      "From State PadState(pad_num=3):\n",
      "  With Action A:\n",
      "    To [State PadState(pad_num=2) and Reward 0.000] with Probability 0.500\n",
      "    To [State PadState(pad_num=4) and Reward 0.000] with Probability 0.500\n",
      "  With Action B:\n",
      "    To [State PadState(pad_num=0) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=1) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=2) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=3) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=4) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=5) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=6) and Reward 1.000] with Probability 0.143\n",
      "From State PadState(pad_num=4):\n",
      "  With Action A:\n",
      "    To [State PadState(pad_num=3) and Reward 0.000] with Probability 0.667\n",
      "    To [State PadState(pad_num=5) and Reward 0.000] with Probability 0.333\n",
      "  With Action B:\n",
      "    To [State PadState(pad_num=0) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=1) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=2) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=3) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=4) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=5) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=6) and Reward 1.000] with Probability 0.143\n",
      "From State PadState(pad_num=5):\n",
      "  With Action A:\n",
      "    To [State PadState(pad_num=4) and Reward 0.000] with Probability 0.833\n",
      "    To [State PadState(pad_num=6) and Reward 1.000] with Probability 0.167\n",
      "  With Action B:\n",
      "    To [State PadState(pad_num=0) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=1) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=2) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=3) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=4) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=5) and Reward 0.000] with Probability 0.143\n",
      "    To [State PadState(pad_num=6) and Reward 1.000] with Probability 0.143\n",
      "PadState(pad_num=0) is a Terminal State\n",
      "PadState(pad_num=6) is a Terminal State\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##test model by printing out map\n",
    "n = 6\n",
    "frog_mdp: FiniteMarkovDecisionProcess[PadState, int] =\\\n",
    "    FrogEscMDP(n=n)\n",
    "\n",
    "print(\"MDP Transition Map\")\n",
    "print(\"------------------\")\n",
    "print(frog_mdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "established-beijing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Map for Policy 1\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 1\n",
      "--------------\n",
      "array([0.38461538, 0.46153846, 0.5       , 0.53846154, 0.61538462])\n",
      "\n",
      "Policy Map for Policy 2\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 2\n",
      "--------------\n",
      "array([0.21276596, 0.25531915, 0.27659574, 0.29787234, 0.34042553])\n",
      "\n",
      "Policy Map for Policy 3\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 3\n",
      "--------------\n",
      "array([0.3125 , 0.375  , 0.40625, 0.4375 , 0.53125])\n",
      "\n",
      "Policy Map for Policy 4\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 4\n",
      "--------------\n",
      "array([0.28571429, 0.34285714, 0.37142857, 0.4       , 0.4       ])\n",
      "\n",
      "Policy Map for Policy 5\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 5\n",
      "--------------\n",
      "array([0.38461538, 0.46153846, 0.5       , 0.53846154, 0.61538462])\n",
      "\n",
      "Policy Map for Policy 6\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 6\n",
      "--------------\n",
      "array([0.33333333, 0.4       , 0.43333333, 0.43333333, 0.43333333])\n",
      "\n",
      "Policy Map for Policy 7\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 7\n",
      "--------------\n",
      "array([0.3626943 , 0.43523316, 0.47150259, 0.47150259, 0.55958549])\n",
      "\n",
      "Policy Map for Policy 8\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 8\n",
      "--------------\n",
      "array([0.33333333, 0.4       , 0.43333333, 0.43333333, 0.43333333])\n",
      "\n",
      "Policy Map for Policy 9\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 9\n",
      "--------------\n",
      "array([0.46875, 0.5625 , 0.59375, 0.625  , 0.6875 ])\n",
      "\n",
      "Policy Map for Policy 10\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 10\n",
      "--------------\n",
      "array([0.38461538, 0.46153846, 0.46153846, 0.46153846, 0.46153846])\n",
      "\n",
      "Policy Map for Policy 11\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 11\n",
      "--------------\n",
      "array([0.41666667, 0.5       , 0.5       , 0.5       , 0.58333333])\n",
      "\n",
      "Policy Map for Policy 12\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 12\n",
      "--------------\n",
      "array([0.38461538, 0.46153846, 0.46153846, 0.46153846, 0.46153846])\n",
      "\n",
      "Policy Map for Policy 13\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 13\n",
      "--------------\n",
      "array([0.44041451, 0.52849741, 0.52849741, 0.56476684, 0.6373057 ])\n",
      "\n",
      "Policy Map for Policy 14\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 14\n",
      "--------------\n",
      "array([0.38461538, 0.46153846, 0.46153846, 0.46153846, 0.46153846])\n",
      "\n",
      "Policy Map for Policy 15\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 15\n",
      "--------------\n",
      "array([0.41666667, 0.5       , 0.5       , 0.5       , 0.58333333])\n",
      "\n",
      "Policy Map for Policy 16\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 16\n",
      "--------------\n",
      "array([0.38461538, 0.46153846, 0.46153846, 0.46153846, 0.46153846])\n",
      "\n",
      "Policy Map for Policy 17\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 17\n",
      "--------------\n",
      "array([0.65957447, 0.70212766, 0.72340426, 0.74468085, 0.78723404])\n",
      "\n",
      "Policy Map for Policy 18\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 18\n",
      "--------------\n",
      "array([0.5, 0.5, 0.5, 0.5, 0.5])\n",
      "\n",
      "Policy Map for Policy 19\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 19\n",
      "--------------\n",
      "array([0.53846154, 0.53846154, 0.53846154, 0.53846154, 0.61538462])\n",
      "\n",
      "Policy Map for Policy 20\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 20\n",
      "--------------\n",
      "array([0.5, 0.5, 0.5, 0.5, 0.5])\n",
      "\n",
      "Policy Map for Policy 21\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 21\n",
      "--------------\n",
      "array([0.56666667, 0.56666667, 0.56666667, 0.6       , 0.66666667])\n",
      "\n",
      "Policy Map for Policy 22\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 22\n",
      "--------------\n",
      "array([0.5, 0.5, 0.5, 0.5, 0.5])\n",
      "\n",
      "Policy Map for Policy 23\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 23\n",
      "--------------\n",
      "array([0.53846154, 0.53846154, 0.53846154, 0.53846154, 0.61538462])\n",
      "\n",
      "Policy Map for Policy 24\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 24\n",
      "--------------\n",
      "array([0.5, 0.5, 0.5, 0.5, 0.5])\n",
      "\n",
      "Policy Map for Policy 25\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 25\n",
      "--------------\n",
      "array([0.6       , 0.6       , 0.62857143, 0.65714286, 0.71428571])\n",
      "\n",
      "Policy Map for Policy 26\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 26\n",
      "--------------\n",
      "array([0.5, 0.5, 0.5, 0.5, 0.5])\n",
      "\n",
      "Policy Map for Policy 27\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 27\n",
      "--------------\n",
      "array([0.53846154, 0.53846154, 0.53846154, 0.53846154, 0.61538462])\n",
      "\n",
      "Policy Map for Policy 28\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 28\n",
      "--------------\n",
      "array([0.5, 0.5, 0.5, 0.5, 0.5])\n",
      "\n",
      "Policy Map for Policy 29\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 29\n",
      "--------------\n",
      "array([0.56666667, 0.56666667, 0.56666667, 0.6       , 0.66666667])\n",
      "\n",
      "Policy Map for Policy 30\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 30\n",
      "--------------\n",
      "array([0.5, 0.5, 0.5, 0.5, 0.5])\n",
      "\n",
      "Policy Map for Policy 31\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 31\n",
      "--------------\n",
      "array([0.53846154, 0.53846154, 0.53846154, 0.53846154, 0.61538462])\n",
      "\n",
      "Policy Map for Policy 32\n",
      "----------\n",
      "For State PadState(pad_num=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State PadState(pad_num=5):\n",
      "  Do Action B with Probability 1.000\n",
      "\n",
      "Implied MRP Policy Evaluation Value Function for Policy 32\n",
      "--------------\n",
      "array([0.5, 0.5, 0.5, 0.5, 0.5])\n",
      "\n",
      "\n",
      "Policy 17 is the optimal deterministic policy\n"
     ]
    }
   ],
   "source": [
    "##create 2^n deterministic policies (as instances of FinitePolicy class)\n",
    "(max_value, max_policy) = (0, 0)\n",
    "for i, policy in enumerate(itertools.product(['A','B'], repeat = n-1), start=1):\n",
    "    frog_fdp: FinitePolicy[PadState, int] = FinitePolicy(\n",
    "    #pad-1 since we dont have a policy for state 0\n",
    "    {PadState(pad_num) : Constant(policy[pad_num-1]) \n",
    "     for pad_num in range(1, n)})\n",
    "\n",
    "    print(f\"Policy Map for Policy {i}\")\n",
    "    print(\"----------\")\n",
    "    print(frog_fdp)\n",
    "    \n",
    "    #create a policy-implied Finite MRP for each of these deterministic policies (using the apply finite policy method of FiniteMarkovDecisionProcess class)\n",
    "    implied_frog_mrp: FiniteMarkovRewardProcess[PadState] =\\\n",
    "        frog_mdp.apply_finite_policy(frog_fdp)\n",
    "\n",
    "    #evaluate the Value Function for each of those implied Finite MRPs (using the get value function vec method of FiniteMarkovRewardProcess class)\n",
    "    print(f\"Implied MRP Policy Evaluation Value Function for Policy {i}\")\n",
    "    print(\"--------------\")\n",
    "    value_func = implied_frog_mrp.get_value_function_vec(gamma=1.0)\n",
    "    pprint(value_func)\n",
    "    print()\n",
    "    \n",
    "    if value_func[0] > max_value:\n",
    "        (max_value, max_policy) = (value_func[0], i)\n",
    "print()\n",
    "print(f\"Policy {max_policy} is the optimal deterministic policy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-blogger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
